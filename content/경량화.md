---
title: LLM 경량화
date: 2024-05-27 15:23
tags:
---

Created at : 2024-05-27 15:23  
Auther: Soo.Y  

# Pruning(가지치기)
- Pruning은 딥 뉴럴 네트워크에서 불필요한 가중치를 제거하는 기법입니다.
- 특정 가중치를 0으로 만들거나 작은 값으로 설정하여 모델 크기를 줄이고 연산량을 감소시킵니다.
- Pruning은 모델의 희소성을 높이는 효과가 있습니다.

# Clustering(군집화)

- Clustering은 가중치를 그룹으로 묶는 기법입니다.
- 유사한 가중치를 하나의 군집으로 묶어서 모델 크기를 줄이고 메모리 사용량을 최적화합니다.
- Clustering은 모델 압축에 도움이 됩니다.

# Quantization(양자화)

- Quantization은 가중치를 정수 또는 작은 비트 수로 표현하는 기법입니다.
- 가중치를 더 작은 메모리 공간에 저장하여 모델 크기를 줄이고 추론 속도를 향상시킵니다.
- Quantization은 일반적으로 정확도 손실을 최소화하면서 모델 크기를 줄이는 데 사용됩니다.


# 관련 문서


